<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="pt-BR" xml:lang="pt-BR"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.23">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>14&nbsp; Estrutura Matricial dos Modelos de Regressão Linear</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 1em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ap_normal.html" rel="next">
<link href="./ap_listas.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-1fe81d0376b2c50856e68e651e390326.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-70a47bd5681a7291082a5b9f83d58762.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Nenhum resultado",
    "search-matching-documents-text": "documentos correspondentes",
    "search-copy-link-title": "Copiar link para a busca",
    "search-hide-matches-text": "Esconder correspondências adicionais",
    "search-more-match-text": "mais correspondência neste documento",
    "search-more-matches-text": "mais correspondências neste documento",
    "search-clear-button-title": "Limpar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Procurar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ap_listas.html">Parte IV — Apêndices</a></li><li class="breadcrumb-item"><a href="./ap_matrizes.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Estrutura Matricial dos Modelos de Regressão Linear</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Procurar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Procurar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Informações Legais e Declaração de Uso de Inteligência Artificial</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prefacio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefácio</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Parte I — Modelagem</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Alternar seção">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introdução e Panorama dos Modelos de Regressão</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modelagem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Modelagem Estatística e Regressão</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./part1_ex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Exercícios e atividades</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Parte II — Modelo de Regressão Linear Simples (MRLS)</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Alternar seção">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mrls.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">O MRLS como Modelo para a Média Condicional</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mrls_emq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Estimação por Mínimos Quadrados no MRLS</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mrls_inferencia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Inferência no MRLS com erros normais</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mrls_testes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Testes de hipóteses e ANOVA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mrls_diagnostico.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Diagnóstico e Avaliação no MRLS</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mrls_transf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Transformações nas Variáveis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mrls_compara.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Comparação de Modelos</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./part2_ex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Exercícios e atividades</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Parte III — Modelo de Regressão Linear Simples (MRLM)</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Alternar seção">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./part3_ex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Exercícios e atividades</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Parte IV — Apêndices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Alternar seção">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ap_listas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Lista de Siglas e Símbolos</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ap_matrizes.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Estrutura Matricial dos Modelos de Regressão Linear</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ap_normal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Distribuição Normal</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ap_forma_linear.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Formas Lineares e Quadráticas na Normal Multivariada</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ap_tratamento.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Tratamento de dados para regressão (pré-modelagem)</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referências</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Índice</h2>
   
  <ul>
  <li><a href="#operações-fundamentais-com-matrizes-e-vetores" id="toc-operações-fundamentais-com-matrizes-e-vetores" class="nav-link active" data-scroll-target="#operações-fundamentais-com-matrizes-e-vetores"><span class="header-section-number">14.1</span> Operações Fundamentais com Matrizes e Vetores</a>
  <ul class="collapse">
  <li><a href="#soma-matricial" id="toc-soma-matricial" class="nav-link" data-scroll-target="#soma-matricial"><span class="header-section-number">14.1.1</span> Soma Matricial</a></li>
  <li><a href="#produto-matricial" id="toc-produto-matricial" class="nav-link" data-scroll-target="#produto-matricial"><span class="header-section-number">14.1.2</span> Produto Matricial</a></li>
  <li><a href="#produto-interno-e-norma" id="toc-produto-interno-e-norma" class="nav-link" data-scroll-target="#produto-interno-e-norma"><span class="header-section-number">14.1.3</span> Produto Interno e Norma</a></li>
  <li><a href="#forma-quadrática" id="toc-forma-quadrática" class="nav-link" data-scroll-target="#forma-quadrática"><span class="header-section-number">14.1.4</span> Forma Quadrática</a></li>
  <li><a href="#transposição" id="toc-transposição" class="nav-link" data-scroll-target="#transposição"><span class="header-section-number">14.1.5</span> Transposição</a></li>
  <li><a href="#inversão" id="toc-inversão" class="nav-link" data-scroll-target="#inversão"><span class="header-section-number">14.1.6</span> Inversão</a></li>
  <li><a href="#propriedades-importantes" id="toc-propriedades-importantes" class="nav-link" data-scroll-target="#propriedades-importantes"><span class="header-section-number">14.1.7</span> Propriedades Importantes</a></li>
  </ul></li>
  <li><a href="#estruturas-matriciais-relevantes" id="toc-estruturas-matriciais-relevantes" class="nav-link" data-scroll-target="#estruturas-matriciais-relevantes"><span class="header-section-number">14.2</span> Estruturas Matriciais Relevantes</a>
  <ul class="collapse">
  <li><a href="#matriz-identidade" id="toc-matriz-identidade" class="nav-link" data-scroll-target="#matriz-identidade"><span class="header-section-number">14.2.1</span> Matriz Identidade</a></li>
  <li><a href="#matrizes-simétricas" id="toc-matrizes-simétricas" class="nav-link" data-scroll-target="#matrizes-simétricas"><span class="header-section-number">14.2.2</span> Matrizes Simétricas</a></li>
  <li><a href="#matrizes-idempotentes" id="toc-matrizes-idempotentes" class="nav-link" data-scroll-target="#matrizes-idempotentes"><span class="header-section-number">14.2.3</span> Matrizes Idempotentes</a></li>
  <li><a href="#matrizes-ortogonais" id="toc-matrizes-ortogonais" class="nav-link" data-scroll-target="#matrizes-ortogonais"><span class="header-section-number">14.2.4</span> Matrizes Ortogonais</a></li>
  <li><a href="#matrizes-diagonais" id="toc-matrizes-diagonais" class="nav-link" data-scroll-target="#matrizes-diagonais"><span class="header-section-number">14.2.5</span> Matrizes Diagonais</a></li>
  <li><a href="#matrizes-definidas-positivas" id="toc-matrizes-definidas-positivas" class="nav-link" data-scroll-target="#matrizes-definidas-positivas"><span class="header-section-number">14.2.6</span> Matrizes Definidas Positivas</a></li>
  </ul></li>
  <li><a href="#estrutura-geométrica-do-modelo-linear" id="toc-estrutura-geométrica-do-modelo-linear" class="nav-link" data-scroll-target="#estrutura-geométrica-do-modelo-linear"><span class="header-section-number">14.3</span> Estrutura Geométrica do Modelo Linear</a>
  <ul class="collapse">
  <li><a href="#espaço-coluna-e-identificabilidade" id="toc-espaço-coluna-e-identificabilidade" class="nav-link" data-scroll-target="#espaço-coluna-e-identificabilidade"><span class="header-section-number">14.3.1</span> Espaço Coluna e Identificabilidade</a></li>
  <li><a href="#o-problema-de-mínimos-quadrados-como-problema-de-projeção" id="toc-o-problema-de-mínimos-quadrados-como-problema-de-projeção" class="nav-link" data-scroll-target="#o-problema-de-mínimos-quadrados-como-problema-de-projeção"><span class="header-section-number">14.3.2</span> O Problema de Mínimos Quadrados como Problema de Projeção</a></li>
  <li><a href="#interpretação-ortogonal-e-soma-direta" id="toc-interpretação-ortogonal-e-soma-direta" class="nav-link" data-scroll-target="#interpretação-ortogonal-e-soma-direta"><span class="header-section-number">14.3.3</span> Interpretação Ortogonal e Soma Direta</a></li>
  <li><a href="#relação-com-posto-e-dimensão" id="toc-relação-com-posto-e-dimensão" class="nav-link" data-scroll-target="#relação-com-posto-e-dimensão"><span class="header-section-number">14.3.4</span> Relação com Posto e Dimensão</a></li>
  <li><a href="#conexão-com-diagnóstico" id="toc-conexão-com-diagnóstico" class="nav-link" data-scroll-target="#conexão-com-diagnóstico"><span class="header-section-number">14.3.5</span> Conexão com Diagnóstico</a></li>
  </ul></li>
  <li><a href="#matrizes-de-projeção-e-decomposição-ortogonal" id="toc-matrizes-de-projeção-e-decomposição-ortogonal" class="nav-link" data-scroll-target="#matrizes-de-projeção-e-decomposição-ortogonal"><span class="header-section-number">14.4</span> Matrizes de Projeção e Decomposição Ortogonal</a></li>
  <li><a href="#diferenciação-matricial-e-estimação-por-mínimos-quadrados" id="toc-diferenciação-matricial-e-estimação-por-mínimos-quadrados" class="nav-link" data-scroll-target="#diferenciação-matricial-e-estimação-por-mínimos-quadrados"><span class="header-section-number">14.5</span> Diferenciação Matricial e Estimação por Mínimos Quadrados</a>
  <ul class="collapse">
  <li><a href="#derivadas-matriciais-fundamentais" id="toc-derivadas-matriciais-fundamentais" class="nav-link" data-scroll-target="#derivadas-matriciais-fundamentais"><span class="header-section-number">14.5.1</span> Derivadas Matriciais Fundamentais</a></li>
  <li><a href="#derivação-das-equações-normais" id="toc-derivação-das-equações-normais" class="nav-link" data-scroll-target="#derivação-das-equações-normais"><span class="header-section-number">14.5.2</span> Derivação das Equações Normais</a></li>
  <li><a href="#interpretação-algébrica" id="toc-interpretação-algébrica" class="nav-link" data-scroll-target="#interpretação-algébrica"><span class="header-section-number">14.5.3</span> Interpretação Algébrica</a></li>
  <li><a href="#interpretação-geométrica-1" id="toc-interpretação-geométrica-1" class="nav-link" data-scroll-target="#interpretação-geométrica-1"><span class="header-section-number">14.5.4</span> Interpretação Geométrica</a></li>
  </ul></li>
  <li><a href="#estrutura-matricial-para-diagnóstico-e-inferência" id="toc-estrutura-matricial-para-diagnóstico-e-inferência" class="nav-link" data-scroll-target="#estrutura-matricial-para-diagnóstico-e-inferência"><span class="header-section-number">14.6</span> Estrutura Matricial para Diagnóstico e Inferência</a>
  <ul class="collapse">
  <li><a href="#alavancagem-e-estrutura-da-matriz-mathbfh" id="toc-alavancagem-e-estrutura-da-matriz-mathbfh" class="nav-link" data-scroll-target="#alavancagem-e-estrutura-da-matriz-mathbfh"><span class="header-section-number">14.6.1</span> Alavancagem e Estrutura da Matriz <span class="math inline">\(\mathbf{H}\)</span></a></li>
  <li><a href="#estrutura-dos-resíduos" id="toc-estrutura-dos-resíduos" class="nav-link" data-scroll-target="#estrutura-dos-resíduos"><span class="header-section-number">14.6.2</span> Estrutura dos Resíduos</a></li>
  <li><a href="#somas-de-quadrados-em-forma-matricial" id="toc-somas-de-quadrados-em-forma-matricial" class="nav-link" data-scroll-target="#somas-de-quadrados-em-forma-matricial"><span class="header-section-number">14.6.3</span> Somas de Quadrados em Forma Matricial</a></li>
  <li><a href="#postos-e-graus-de-liberdade" id="toc-postos-e-graus-de-liberdade" class="nav-link" data-scroll-target="#postos-e-graus-de-liberdade"><span class="header-section-number">14.6.4</span> Postos e Graus de Liberdade</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ap_listas.html">Parte IV — Apêndices</a></li><li class="breadcrumb-item"><a href="./ap_matrizes.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Estrutura Matricial dos Modelos de Regressão Linear</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Estrutura Matricial dos Modelos de Regressão Linear</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>A formulação moderna dos modelos de regressão linear é essencialmente matricial. Essa notação vetorial revela a estrutura geométrica do problema de estimação, explicita as condições necessárias para identificabilidade dos parâmetros e permite analisar propriedades estatísticas dos estimadores de forma sistemática (ver <span class="citation" data-cites="harville1997">Harville (<a href="references.html#ref-harville1997" role="doc-biblioref">1997</a>)</span>).</p>
<p>Este apêndice consolida os principais elementos de Álgebra Linear utilizados ao longo do estudo de regressão, com ênfase nas estruturas que reaparecem na estimação por mínimos quadrados, na inferência e na análise de diagnóstico.</p>
<section id="operações-fundamentais-com-matrizes-e-vetores" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="operações-fundamentais-com-matrizes-e-vetores"><span class="header-section-number">14.1</span> Operações Fundamentais com Matrizes e Vetores</h2>
<p>A linguagem matricial é uma forma compacta de escrever o modelo de regressão que permite enxergar o problema como um problema geométrico em <span class="math inline">\(\mathbb{R}^n\)</span>. Cada vetor corresponde a um ponto ou direção nesse espaço, e cada matriz representa uma transformação linear.</p>
<p>Sejam <span class="math inline">\(\mathbf{A}\)</span> e <span class="math inline">\(\mathbf{B}\)</span> matrizes de dimensões compatíveis e <span class="math inline">\(\mathbf{x}, \mathbf{y}\)</span> vetores coluna em <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
<p>Para fixar ideias, considere explicitamente:</p>
<p><span class="math display">\[
\mathbf{x} =
\begin{bmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{bmatrix},
\qquad
\mathbf{y} =
\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n
\end{bmatrix}.
\]</span></p>
<section id="soma-matricial" class="level3" data-number="14.1.1">
<h3 data-number="14.1.1" class="anchored" data-anchor-id="soma-matricial"><span class="header-section-number">14.1.1</span> Soma Matricial</h3>
<p>Se</p>
<p><span class="math display">\[
\mathbf{A} =
\begin{bmatrix}
a_{11} &amp; a_{12} \\
a_{21} &amp; a_{22}
\end{bmatrix},
\qquad
\mathbf{B} =
\begin{bmatrix}
b_{11} &amp; b_{12} \\
b_{21} &amp; b_{22}
\end{bmatrix},
\]</span></p>
<p>então</p>
<p><span class="math display">\[
\mathbf{A} + \mathbf{B}
=
\begin{bmatrix}
a_{11}+b_{11} &amp; a_{12}+b_{12} \\
a_{21}+b_{21} &amp; a_{22}+b_{22}
\end{bmatrix}.
\]</span></p>
<p>A soma é definida elemento a elemento e exige dimensões idênticas.</p>
</section>
<section id="produto-matricial" class="level3" data-number="14.1.2">
<h3 data-number="14.1.2" class="anchored" data-anchor-id="produto-matricial"><span class="header-section-number">14.1.2</span> Produto Matricial</h3>
<p>Se</p>
<p><span class="math display">\[
\mathbf{A} =
\begin{bmatrix}
a_{11} &amp; a_{12} \\
a_{21} &amp; a_{22}
\end{bmatrix},
\qquad
\mathbf{B} =
\begin{bmatrix}
b_{11} &amp; b_{12} \\
b_{21} &amp; b_{22}
\end{bmatrix},
\]</span></p>
<p>então</p>
<p><span class="math display">\[
\mathbf{A}\mathbf{B}
=
\begin{bmatrix}
a_{11}b_{11}+a_{12}b_{21} &amp; a_{11}b_{12}+a_{12}b_{22} \\
a_{21}b_{11}+a_{22}b_{21} &amp; a_{21}b_{12}+a_{22}b_{22}
\end{bmatrix}.
\]</span></p>
<p>O produto matricial corresponde à composição de transformações lineares.<br>
No modelo linear</p>
<p><span class="math display">\[
\mathbf{Y} = \mathbf{X}\boldsymbol{\beta},
\]</span></p>
<p>a matriz <span class="math inline">\(\mathbf{X}\)</span>, de dimensão <span class="math inline">\(n \times (p+1)\)</span> transforma o vetor de parâmetros <span class="math inline">\(\boldsymbol{\beta}\)</span>, de dimensão <span class="math inline">\((p+1) \times 1\)</span> em um vetor no espaço das respostas. Assim, <span class="math inline">\(\mathbf{X}\)</span> pode ser interpretada como uma transformação que leva parâmetros em <span class="math inline">\(\mathbb{R}^{p+1}\)</span> para vetores ajustados em <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
</section>
<section id="produto-interno-e-norma" class="level3" data-number="14.1.3">
<h3 data-number="14.1.3" class="anchored" data-anchor-id="produto-interno-e-norma"><span class="header-section-number">14.1.3</span> Produto Interno e Norma</h3>
<p>O produto interno entre vetores é dado por</p>
<p><span class="math display">\[
\mathbf{x}^\top \mathbf{y}
=
\sum_{i=1}^n x_i y_i.
\]</span></p>
<p>Quando <span class="math inline">\(\mathbf{x} = \mathbf{y}\)</span>, obtemos</p>
<p><span class="math display">\[
\mathbf{x}^\top \mathbf{x}
=
\sum_{i=1}^n x_i^2,
\]</span></p>
<p>que define o quadrado da norma euclidiana:</p>
<p><span class="math display">\[
\|\mathbf{x}\|^2 = \mathbf{x}^\top \mathbf{x}.
\]</span></p>
<p>Essa noção de norma é central na regressão, pois a estimação por mínimos quadrados consiste em minimizar</p>
<p><span class="math display">\[
\|\mathbf{Y} - \mathbf{X}\boldsymbol{\beta}\|^2.
\]</span></p>
<p>Portanto, o problema de estimação é um problema geométrico de minimizar distância no espaço <span class="math inline">\(\mathbb{R}^n\)</span>. A formulação geométrica da regressão em termos de subespaços e projeções é desenvolvida em detalhe em <span class="citation" data-cites="harville1997">Harville (<a href="references.html#ref-harville1997" role="doc-biblioref">1997</a>)</span>.</p>
</section>
<section id="forma-quadrática" class="level3" data-number="14.1.4">
<h3 data-number="14.1.4" class="anchored" data-anchor-id="forma-quadrática"><span class="header-section-number">14.1.4</span> Forma Quadrática</h3>
<p>Uma expressão da forma</p>
<p><span class="math display">\[
\mathbf{x}^\top \mathbf{A}\mathbf{x}
\]</span></p>
<p>é chamada forma quadrática.</p>
<p>Para visualizar, considere</p>
<p><span class="math display">\[
\mathbf{x} =
\begin{bmatrix}
x_1 \\
x_2
\end{bmatrix},
\qquad
\mathbf{A} =
\begin{bmatrix}
a &amp; b \\
b &amp; c
\end{bmatrix}.
\]</span></p>
<p>Então</p>
<p><span class="math display">\[
\mathbf{x}^\top \mathbf{A}\mathbf{x}
=
a x_1^2 + 2b x_1 x_2 + c x_2^2.
\]</span></p>
<p>Observe que surgem termos quadráticos e termos mistos. Em regressão, as somas de quadrados explicada e residual podem ser escritas exatamente como formas quadráticas do vetor <span class="math inline">\(\mathbf{Y}\)</span> (ver <span class="citation" data-cites="rencher2012">Rencher; Christensen (<a href="references.html#ref-rencher2012" role="doc-biblioref">2012</a>)</span>).</p>
</section>
<section id="transposição" class="level3" data-number="14.1.5">
<h3 data-number="14.1.5" class="anchored" data-anchor-id="transposição"><span class="header-section-number">14.1.5</span> Transposição</h3>
<p>A transposta de uma matriz é obtida trocando linhas por colunas:</p>
<p><span class="math display">\[
\mathbf{A} =
\begin{bmatrix}
a_{11} &amp; a_{12} \\
a_{21} &amp; a_{22}
\end{bmatrix}
\quad
\Rightarrow
\quad
\mathbf{A}^\top =
\begin{bmatrix}
a_{11} &amp; a_{21} \\
a_{12} &amp; a_{22}
\end{bmatrix}.
\]</span></p>
<p>A transposição é essencial para definir produtos internos e garantir que expressões como <span class="math inline">\(\mathbf{X}^\top\mathbf{X}\)</span> sejam matrizes quadradas.</p>
</section>
<section id="inversão" class="level3" data-number="14.1.6">
<h3 data-number="14.1.6" class="anchored" data-anchor-id="inversão"><span class="header-section-number">14.1.6</span> Inversão</h3>
<p>Uma matriz quadrada <span class="math inline">\(\mathbf{A}\)</span> é invertível se existe <span class="math inline">\(\mathbf{A}^{-1}\)</span> tal que</p>
<p><span class="math display">\[
\mathbf{A}^{-1}\mathbf{A} = \mathbf{A}\mathbf{A}^{-1} = \mathbf{I}.
\]</span></p>
<p>Por exemplo, para uma matriz <span class="math inline">\(2 \times 2\)</span>,</p>
<p><span class="math display">\[
\mathbf{A} =
\begin{bmatrix}
a &amp; b \\
c &amp; d
\end{bmatrix},
\]</span></p>
<p>se <span class="math inline">\(ad - bc \neq 0\)</span>, então</p>
<p><span class="math display">\[
\mathbf{A}^{-1}
=
\frac{1}{ad-bc}
\begin{bmatrix}
d &amp; -b \\
-c &amp; a
\end{bmatrix}.
\]</span></p>
<p>Na regressão, a invertibilidade de <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span> é condição necessária para a existência do estimador de mínimos quadrados único.Para o caso de posto deficiente e o uso de decomposição SVD e pseudoinversas, ver <span class="citation" data-cites="golub2013">Golub; Van Loan (<a href="references.html#ref-golub2013" role="doc-biblioref">2013</a>)</span>.</p>
</section>
<section id="propriedades-importantes" class="level3" data-number="14.1.7">
<h3 data-number="14.1.7" class="anchored" data-anchor-id="propriedades-importantes"><span class="header-section-number">14.1.7</span> Propriedades Importantes</h3>
<p>Duas identidades frequentemente utilizadas são</p>
<p><span class="math display">\[
(\mathbf{A}\mathbf{B})^\top = \mathbf{B}^\top \mathbf{A}^\top,
\qquad
(\mathbf{A}^{-1})^\top = (\mathbf{A}^\top)^{-1}.
\]</span></p>
<p>Essas propriedades são fundamentais na dedução de resultados como:</p>
<p><span class="math display">\[
\mathrm{Var}(\hat{\boldsymbol{\beta}})
=
\sigma^2 (\mathbf{X}^\top \mathbf{X})^{-1},
\]</span></p>
<p>e na demonstração das propriedades das matrizes de projeção.</p>
<p>Essas operações constituem o mecanismo estrutural que permitirá:</p>
<ul>
<li>interpretar o estimador como projeção ortogonal;</li>
<li>escrever somas de quadrados como formas quadráticas;</li>
<li>analisar variâncias e covariâncias de estimadores;</li>
<li>compreender a geometria do ajuste e do diagnóstico.</li>
</ul>
<p>Nos itens seguintes, essas operações serão organizadas dentro da estrutura específica do modelo linear múltiplo.</p>
</section>
</section>
<section id="estruturas-matriciais-relevantes" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="estruturas-matriciais-relevantes"><span class="header-section-number">14.2</span> Estruturas Matriciais Relevantes</h2>
<p>Determinados tipos de matrizes surgem de forma recorrente na teoria da regressão linear. Cada uma delas corresponde a uma propriedade geométrica ou estatística que será explorada na estimação, na inferência e na análise de diagnóstico.</p>
<p>A tabela a seguir resume algumas dessas estruturas fundamentais.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 36%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th>Tipo</th>
<th>Definição</th>
<th>Relevância</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Identidade <span class="math inline">\(\mathbf{I}_n\)</span></td>
<td>Diagonal principal composta por 1’s</td>
<td>Elemento neutro da multiplicação</td>
</tr>
<tr class="even">
<td>Simétrica</td>
<td><span class="math inline">\(\mathbf{A} = \mathbf{A}^\top\)</span></td>
<td>Autovalores reais</td>
</tr>
<tr class="odd">
<td>Idempotente</td>
<td><span class="math inline">\(\mathbf{A}^2 = \mathbf{A}\)</span></td>
<td>Projeções</td>
</tr>
<tr class="even">
<td>Ortogonal</td>
<td><span class="math inline">\(\mathbf{A}^\top \mathbf{A} = \mathbf{I}\)</span></td>
<td>Preserva norma</td>
</tr>
<tr class="odd">
<td>Diagonal</td>
<td>Elementos fora da diagonal iguais a zero</td>
<td>Simplifica formas quadráticas</td>
</tr>
<tr class="even">
<td>Definida positiva</td>
<td><span class="math inline">\(\mathbf{x}^\top \mathbf{A}\mathbf{x} &gt; 0\)</span> para todo <span class="math inline">\(\mathbf{x}\neq 0\)</span></td>
<td>Garantia de invertibilidade e convexidade</td>
</tr>
</tbody>
</table>
<p>A seguir, detalham-se as propriedades e implicações dessas estruturas no contexto do modelo linear.</p>
<section id="matriz-identidade" class="level3" data-number="14.2.1">
<h3 data-number="14.2.1" class="anchored" data-anchor-id="matriz-identidade"><span class="header-section-number">14.2.1</span> Matriz Identidade</h3>
<p>A matriz identidade de ordem <span class="math inline">\(n\)</span> é dada por</p>
<p><span class="math display">\[
\mathbf{I}_n =
\begin{bmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; 1
\end{bmatrix}.
\]</span></p>
<p>Ela satisfaz</p>
<p><span class="math display">\[
\mathbf{I}_n \mathbf{x} = \mathbf{x}
\quad
\text{para todo } \mathbf{x} \in \mathbb{R}^n.
\]</span></p>
<p>No modelo linear, a identidade aparece, por exemplo, na matriz de covariância dos erros sob homocedasticidade:</p>
<p><span class="math display">\[
\mathrm{Cov}(\boldsymbol{\varepsilon}) = \sigma^2 \mathbf{I}_n.
\]</span></p>
<p>Sob normalidade, essa estrutura implica independência e variância constante dos erros.</p>
</section>
<section id="matrizes-simétricas" class="level3" data-number="14.2.2">
<h3 data-number="14.2.2" class="anchored" data-anchor-id="matrizes-simétricas"><span class="header-section-number">14.2.2</span> Matrizes Simétricas</h3>
<p>Uma matriz é simétrica se</p>
<p><span class="math display">\[
\mathbf{A} = \mathbf{A}^\top.
\]</span></p>
<p>Por exemplo,</p>
<p><span class="math display">\[
\mathbf{A} =
\begin{bmatrix}
2 &amp; -1 \\
-1 &amp; 3
\end{bmatrix}
\]</span></p>
<p>é simétrica.</p>
<p>Matrizes simétricas possuem autovalores reais e podem ser diagonalizadas por matrizes ortogonais. Essa propriedade é crucial para compreender a decomposição espectral de <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span> e analisar problemas como multicolinearidade (ver <span class="citation" data-cites="harville1997">Harville (<a href="references.html#ref-harville1997" role="doc-biblioref">1997</a>)</span>).</p>
<p>No modelo linear, as matrizes <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span>, <span class="math inline">\(\mathbf{H}\)</span> e <span class="math inline">\(\mathbf{M}\)</span> são simétricas.</p>
</section>
<section id="matrizes-idempotentes" class="level3" data-number="14.2.3">
<h3 data-number="14.2.3" class="anchored" data-anchor-id="matrizes-idempotentes"><span class="header-section-number">14.2.3</span> Matrizes Idempotentes</h3>
<p>Uma matriz é idempotente se</p>
<p><span class="math display">\[
\mathbf{A}^2 = \mathbf{A}.
\]</span></p>
<p>Isso implica que aplicar a transformação duas vezes produz o mesmo resultado que aplicá-la uma vez.</p>
<p>Por exemplo, a matriz</p>
<p><span class="math display">\[
\mathbf{P} =
\begin{bmatrix}
1 &amp; 0 \\
0 &amp; 0
\end{bmatrix}
\]</span></p>
<p>é idempotente.</p>
<p>No modelo linear, a matriz de projeção</p>
<p><span class="math display">\[
\mathbf{H} = \mathbf{X}(\mathbf{X}^\top \mathbf{X})^{-1}\mathbf{X}^\top
\]</span></p>
<p>satisfaz</p>
<p><span class="math display">\[
\mathbf{H}^2 = \mathbf{H}.
\]</span></p>
<p>Isso significa que <span class="math inline">\(\mathbf{H}\)</span> projeta vetores no subespaço <span class="math inline">\(\mathrm{col}(\mathbf{X})\)</span>. Uma vez projetado, aplicar novamente a projeção não altera o vetor.</p>
<p>Essa propriedade é fundamental para compreender:</p>
<ul>
<li>decomposição ortogonal;</li>
<li>independência entre componentes projetadas sob normalidade;</li>
<li>decomposição da soma de quadrados total.</li>
</ul>
</section>
<section id="matrizes-ortogonais" class="level3" data-number="14.2.4">
<h3 data-number="14.2.4" class="anchored" data-anchor-id="matrizes-ortogonais"><span class="header-section-number">14.2.4</span> Matrizes Ortogonais</h3>
<p>Uma matriz <span class="math inline">\(\mathbf{Q}\)</span> é ortogonal se</p>
<p><span class="math display">\[
\mathbf{Q}^\top \mathbf{Q} = \mathbf{I}.
\]</span></p>
<p>Isso implica que</p>
<p><span class="math display">\[
\|\mathbf{Q}\mathbf{x}\| = \|\mathbf{x}\|.
\]</span></p>
<p>Ou seja, matrizes ortogonais preservam comprimentos e ângulos.</p>
<p>Essa propriedade é central na decomposição espectral de matrizes simétricas:</p>
<p><span class="math display">\[
\mathbf{A} = \mathbf{Q}\boldsymbol{\Lambda}\mathbf{Q}^\top,
\]</span></p>
<p>em que <span class="math inline">\(\boldsymbol{\Lambda}\)</span> é diagonal contendo os autovalores.A análise numérica dessas decomposições é tratada em profundidade em <span class="citation" data-cites="golub2013">Golub; Van Loan (<a href="references.html#ref-golub2013" role="doc-biblioref">2013</a>)</span>.</p>
<p>Na regressão, essa decomposição permite analisar:</p>
<ul>
<li>a estrutura de <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span>;</li>
<li>a estabilidade numérica da estimação;</li>
<li>o efeito da multicolinearidade.</li>
</ul>
</section>
<section id="matrizes-diagonais" class="level3" data-number="14.2.5">
<h3 data-number="14.2.5" class="anchored" data-anchor-id="matrizes-diagonais"><span class="header-section-number">14.2.5</span> Matrizes Diagonais</h3>
<p>Uma matriz diagonal possui a forma</p>
<p><span class="math display">\[
\mathbf{D} =
\begin{bmatrix}
d_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; d_2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; d_n
\end{bmatrix}.
\]</span></p>
<p>Formas quadráticas envolvendo matrizes diagonais simplificam-se para</p>
<p><span class="math display">\[
\mathbf{x}^\top \mathbf{D}\mathbf{x}
=
\sum_{i=1}^n d_i x_i^2.
\]</span></p>
<p>Essa simplificação é útil na análise de variâncias e na interpretação de decomposições espectrais.</p>
</section>
<section id="matrizes-definidas-positivas" class="level3" data-number="14.2.6">
<h3 data-number="14.2.6" class="anchored" data-anchor-id="matrizes-definidas-positivas"><span class="header-section-number">14.2.6</span> Matrizes Definidas Positivas</h3>
<p>Uma matriz simétrica <span class="math inline">\(\mathbf{A}\)</span> é definida positiva se</p>
<p><span class="math display">\[
\mathbf{x}^\top \mathbf{A}\mathbf{x} &gt; 0
\quad
\text{para todo } \mathbf{x} \neq \mathbf{0}.
\]</span></p>
<p>Equivalentemente, todos os seus autovalores são positivos.</p>
<p>Essa propriedade possui consequências fundamentais:</p>
<ol type="1">
<li><span class="math inline">\(\mathbf{A}\)</span> é invertível;</li>
<li>a função <span class="math inline">\(\mathbf{x}^\top \mathbf{A}\mathbf{x}\)</span> é estritamente convexa;</li>
<li>problemas de minimização associados possuem solução única.</li>
</ol>
<p>No modelo de regressão linear, a matriz</p>
<p><span class="math display">\[
\mathbf{X}^\top \mathbf{X}
\]</span></p>
<p>é simétrica e definida positiva se, e somente se, as colunas de <span class="math inline">\(\mathbf{X}\)</span> forem linearmente independentes. Isso equivale à condição</p>
<p><span class="math display">\[
\operatorname{rank}(\mathbf{X}) = p+1.
\]</span></p>
<p>Quando essa condição é satisfeita, o estimador de mínimos quadrados</p>
<p><span class="math display">\[
\hat{\boldsymbol{\beta}}
=
(\mathbf{X}^\top \mathbf{X})^{-1}\mathbf{X}^\top \mathbf{Y}
\]</span></p>
<p>existe e é único.</p>
<p>Se <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span> não for definida positiva, o problema de estimação perde identificabilidade, caracterizando multicolinearidade perfeita.</p>
<p>A compreensão dessas estruturas matriciais permite interpretar o modelo linear como:</p>
<ul>
<li>um problema geométrico de projeção em subespaços;</li>
<li>um problema analítico de minimização convexa;</li>
<li>um problema espectral envolvendo autovalores e autovetores.</li>
</ul>
<p>Essas perspectivas convergem na teoria de estimação, inferência e diagnóstico.</p>
</section>
</section>
<section id="estrutura-geométrica-do-modelo-linear" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="estrutura-geométrica-do-modelo-linear"><span class="header-section-number">14.3</span> Estrutura Geométrica do Modelo Linear</h2>
<p>Considere o modelo linear múltiplo em notação matricial:</p>
<p><span class="math display">\[
\mathbf{Y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\varepsilon},
\]</span></p>
<p>em que</p>
<ul>
<li><span class="math inline">\(\mathbf{Y} \in \mathbb{R}^n\)</span> é o vetor de respostas observadas,</li>
<li><span class="math inline">\(\mathbf{X} \in \mathbb{R}^{n \times (p+1)}\)</span> é a matriz de planejamento,</li>
<li><span class="math inline">\(\boldsymbol{\beta} \in \mathbb{R}^{p+1}\)</span> é o vetor de parâmetros,</li>
<li><span class="math inline">\(\boldsymbol{\varepsilon} \in \mathbb{R}^n\)</span> é o vetor de erros.</li>
</ul>
<p>Explicitamente, pode-se escrever</p>
<p><span class="math display">\[
\mathbf{X}
=
\begin{bmatrix}
1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} \\
1 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}
\end{bmatrix},
\qquad
\boldsymbol{\beta}
=
\begin{bmatrix}
\beta_0 \\
\beta_1 \\
\vdots \\
\beta_p
\end{bmatrix}.
\]</span></p>
<p>Cada coluna de <span class="math inline">\(\mathbf{X}\)</span> é um vetor em <span class="math inline">\(\mathbb{R}^n\)</span>. Assim, <span class="math inline">\(\mathbf{X}\)</span> pode ser vista como um conjunto de <span class="math inline">\(p+1\)</span> vetores que geram um subespaço de <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
<section id="espaço-coluna-e-identificabilidade" class="level3" data-number="14.3.1">
<h3 data-number="14.3.1" class="anchored" data-anchor-id="espaço-coluna-e-identificabilidade"><span class="header-section-number">14.3.1</span> Espaço Coluna e Identificabilidade</h3>
<p>O <strong>espaço coluna</strong> de <span class="math inline">\(\mathbf{X}\)</span> é definido como</p>
<p><span class="math display">\[
\mathrm{col}(\mathbf{X})
=
\left\{
\mathbf{X}\boldsymbol{\beta}
:
\boldsymbol{\beta} \in \mathbb{R}^{p+1}
\right\}.
\]</span></p>
<p>Esse conjunto é um subespaço vetorial de <span class="math inline">\(\mathbb{R}^n\)</span>, cujo posto é</p>
<p><span class="math display">\[
\operatorname{rank}(\mathbf{X}) \leq p+1.
\]</span></p>
<p>Se as colunas de <span class="math inline">\(\mathbf{X}\)</span> forem linearmente independentes, então</p>
<p><span class="math display">\[
\operatorname{rank}(\mathbf{X}) = p+1,
\]</span></p>
<p>e o espaço coluna tem dimensão <span class="math inline">\(p+1\)</span>.</p>
<p>Essa condição é equivalente à positividade definida de <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span> e garante a identificabilidade única dos parâmetros.</p>
</section>
<section id="o-problema-de-mínimos-quadrados-como-problema-de-projeção" class="level3" data-number="14.3.2">
<h3 data-number="14.3.2" class="anchored" data-anchor-id="o-problema-de-mínimos-quadrados-como-problema-de-projeção"><span class="header-section-number">14.3.2</span> O Problema de Mínimos Quadrados como Problema de Projeção</h3>
<p>O estimador de mínimos quadrados é definido como a solução do problema</p>
<p><span class="math display">\[
\min_{\boldsymbol{\beta}}
\|\mathbf{Y} - \mathbf{X}\boldsymbol{\beta}\|^2.
\]</span></p>
<p>Geometricamente, isso significa encontrar o vetor em <span class="math inline">\(\mathrm{col}(\mathbf{X})\)</span> que esteja mais próximo de <span class="math inline">\(\mathbf{Y}\)</span> na métrica euclidiana.</p>
<p>Seja</p>
<p><span class="math display">\[
\hat{\mathbf{Y}} = \mathbf{X}\hat{\boldsymbol{\beta}}.
\]</span></p>
<p>Então</p>
<p><span class="math display">\[
\hat{\mathbf{Y}} \in \mathrm{col}(\mathbf{X})
\]</span></p>
<p>e</p>
<p><span class="math display">\[
\mathbf{Y} - \hat{\mathbf{Y}}
\perp
\mathrm{col}(\mathbf{X}).
\]</span></p>
<p>Ou seja,</p>
<p><span class="math display">\[
\mathbf{X}^\top(\mathbf{Y} - \hat{\mathbf{Y}}) = \mathbf{0}.
\]</span></p>
<p>Essa condição é exatamente a forma matricial das equações normais.</p>
</section>
<section id="interpretação-ortogonal-e-soma-direta" class="level3" data-number="14.3.3">
<h3 data-number="14.3.3" class="anchored" data-anchor-id="interpretação-ortogonal-e-soma-direta"><span class="header-section-number">14.3.3</span> Interpretação Ortogonal e Soma Direta</h3>
<p>Seja <span class="math inline">\(V = \mathbb{R}^n\)</span> equipado com o produto interno usual <span class="math display">\[
\langle \mathbf{x}, \mathbf{y} \rangle = \mathbf{x}^\top \mathbf{y}.
\]</span></p>
<p>Se <span class="math inline">\(S\)</span> é um subespaço de <span class="math inline">\(\mathbb{R}^n\)</span>, define-se seu complemento ortogonal como</p>
<p><span class="math display">\[
S^\perp
=
\left\{
\mathbf{z} \in \mathbb{R}^n :
\mathbf{z}^\top \mathbf{s} = 0
\ \text{para todo } \mathbf{s} \in S
\right\}.
\]</span></p>
<p>Diz-se que <span class="math inline">\(\mathbb{R}^n\)</span> é a <strong>soma direta ortogonal</strong> de dois subespaços <span class="math inline">\(S\)</span> e <span class="math inline">\(T\)</span> se:</p>
<ol type="1">
<li>todo vetor de <span class="math inline">\(\mathbb{R}^n\)</span> pode ser escrito como soma de um vetor em <span class="math inline">\(S\)</span> e um vetor em <span class="math inline">\(T\)</span>;</li>
<li>essa decomposição é única;</li>
<li><span class="math inline">\(S\)</span> e <span class="math inline">\(T\)</span> são ortogonais, isto é, <span class="math inline">\(\mathbf{s}^\top \mathbf{t} = 0\)</span> para todo <span class="math inline">\(\mathbf{s}\in S\)</span> e <span class="math inline">\(\mathbf{t}\in T\)</span>.</li>
</ol>
<p>Nessa situação escreve-se</p>
<p><span class="math display">\[
\mathbb{R}^n = S \oplus T,
\]</span></p>
<p>em que o símbolo <span class="math inline">\(\oplus\)</span> indica soma direta.</p>
<p>No contexto do modelo linear, tomando</p>
<p><span class="math display">\[
S = \mathrm{col}(\mathbf{X}),
\qquad
T = \mathrm{col}(\mathbf{X})^\perp,
\]</span></p>
<p>obtém-se</p>
<p><span class="math display">\[
\mathbb{R}^n
=
\mathrm{col}(\mathbf{X})
\oplus
\mathrm{col}(\mathbf{X})^\perp.
\]</span></p>
<p>Isso significa que qualquer vetor <span class="math inline">\(\mathbf{Y} \in \mathbb{R}^n\)</span> pode ser decomposto de maneira única como</p>
<p><span class="math display">\[
\mathbf{Y}
=
\hat{\mathbf{Y}}
+
\hat{\boldsymbol{\varepsilon}},
\]</span></p>
<p>onde</p>
<ul>
<li><span class="math inline">\(\hat{\mathbf{Y}} \in \mathrm{col}(\mathbf{X})\)</span>,</li>
<li><span class="math inline">\(\hat{\boldsymbol{\varepsilon}} \in \mathrm{col}(\mathbf{X})^\perp\)</span>.</li>
</ul>
<p>A ortogonalidade implica</p>
<p><span class="math display">\[
\hat{\mathbf{Y}}^\top \hat{\boldsymbol{\varepsilon}} = 0,
\]</span></p>
<p>ou, equivalentemente,</p>
<p><span class="math display">\[
\mathbf{X}^\top \hat{\boldsymbol{\varepsilon}} = \mathbf{0}.
\]</span></p>
<p>Essa decomposição é puramente geométrica e independe de qualquer hipótese probabilística sobre os erros. Ela constitui o núcleo estrutural do método de mínimos quadrados e fundamenta:</p>
<ul>
<li>a decomposição da soma de quadrados total;</li>
<li>a contagem de graus de liberdade;</li>
<li>a independência entre componentes projetadas sob normalidade.</li>
</ul>
<p>Assim, o modelo linear pode ser interpretado como a decomposição ortogonal do vetor de respostas em duas componentes pertencentes a subespaços complementares.</p>
</section>
<section id="relação-com-posto-e-dimensão" class="level3" data-number="14.3.4">
<h3 data-number="14.3.4" class="anchored" data-anchor-id="relação-com-posto-e-dimensão"><span class="header-section-number">14.3.4</span> Relação com Posto e Dimensão</h3>
<p>Se <span class="math inline">\(\operatorname{rank}(\mathbf{X}) = r\)</span>, então:</p>
<ul>
<li><span class="math inline">\(\dim(\mathrm{col}(\mathbf{X})) = r\)</span>,</li>
<li><span class="math inline">\(\dim(\mathrm{col}(\mathbf{X})^\perp) = n - r\)</span>.</li>
</ul>
<p>No modelo linear completo com intercepto e colunas independentes,</p>
<p><span class="math display">\[
r = p+1,
\]</span></p>
<p>e, portanto, o espaço residual tem dimensão</p>
<p><span class="math display">\[
n - (p+1).
\]</span></p>
<p>Essa contagem de dimensões será reinterpretada mais adiante como graus de liberdade na decomposição das somas de quadrados.</p>
</section>
<section id="conexão-com-diagnóstico" class="level3" data-number="14.3.5">
<h3 data-number="14.3.5" class="anchored" data-anchor-id="conexão-com-diagnóstico"><span class="header-section-number">14.3.5</span> Conexão com Diagnóstico</h3>
<p>A estrutura geométrica permite compreender diversos elementos de diagnóstico:</p>
<ul>
<li>Vetores de alta alavancagem correspondem a observações cuja projeção sobre <span class="math inline">\(\mathrm{col}(\mathbf{X})\)</span> é dominante.</li>
<li>Resíduos grandes correspondem a componentes significativas no subespaço ortogonal.</li>
<li>A decomposição da variabilidade total decorre da ortogonalidade entre componentes projetadas.</li>
</ul>
<p>O modelo linear é, portato, uma decomposição geométrica do vetor de respostas em dois componentes ortogonais.</p>
</section>
</section>
<section id="matrizes-de-projeção-e-decomposição-ortogonal" class="level2" data-number="14.4">
<h2 data-number="14.4" class="anchored" data-anchor-id="matrizes-de-projeção-e-decomposição-ortogonal"><span class="header-section-number">14.4</span> Matrizes de Projeção e Decomposição Ortogonal</h2>
<p>A matriz de projeção associada ao modelo linear múltiplo é definida por</p>
<p><span class="math display">\[
\mathbf{H}
=
\mathbf{X}(\mathbf{X}^\top \mathbf{X})^{-1}\mathbf{X}^\top.
\]</span></p>
<p>Essa matriz desempenha papel relevante na teoria da regressão, pois formaliza algebricamente a projeção ortogonal sobre o subespaço <span class="math inline">\(\mathrm{col}(\mathbf{X})\)</span>.</p>
<section id="verificação-das-propriedades-estruturais" class="level4" data-number="14.4.0.1">
<h4 data-number="14.4.0.1" class="anchored" data-anchor-id="verificação-das-propriedades-estruturais"><span class="header-section-number">14.4.0.1</span> Verificação das Propriedades Estruturais</h4>
<p><strong>Simetria</strong></p>
<p><span class="math display">\[
\mathbf{H}^\top
=
\left[
\mathbf{X}(\mathbf{X}^\top \mathbf{X})^{-1}\mathbf{X}^\top
\right]^\top
=
\mathbf{X}(\mathbf{X}^\top \mathbf{X})^{-1}\mathbf{X}^\top
=
\mathbf{H}.
\]</span></p>
<p>Utilizou-se o fato de que <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span> é simétrica e que a transposta de um produto inverte a ordem dos fatores.</p>
<p><strong>Idempotência</strong></p>
<p><span class="math display">\[
\mathbf{H}^2
=
\mathbf{X}(\mathbf{X}^\top \mathbf{X})^{-1}\mathbf{X}^\top
\mathbf{X}(\mathbf{X}^\top \mathbf{X})^{-1}\mathbf{X}^\top.
\]</span></p>
<p>Como</p>
<p><span class="math display">\[
\mathbf{X}^\top \mathbf{X}(\mathbf{X}^\top \mathbf{X})^{-1}
=
\mathbf{I},
\]</span></p>
<p>segue que</p>
<p><span class="math display">\[
\mathbf{H}^2
=
\mathbf{X}(\mathbf{X}^\top \mathbf{X})^{-1}\mathbf{X}^\top
=
\mathbf{H}.
\]</span></p>
<p>A idempotência caracteriza transformações que, uma vez aplicadas, não alteram mais o vetor.</p>
</section>
<section id="interpretação-geométrica" class="level4" data-number="14.4.0.2">
<h4 data-number="14.4.0.2" class="anchored" data-anchor-id="interpretação-geométrica"><span class="header-section-number">14.4.0.2</span> Interpretação Geométrica</h4>
<p>Para qualquer vetor <span class="math inline">\(\mathbf{y} \in \mathbb{R}^n\)</span>,</p>
<p><span class="math display">\[
\mathbf{H}\mathbf{y}
\in
\mathrm{col}(\mathbf{X}).
\]</span></p>
<p>Além disso,</p>
<p><span class="math display">\[
\mathbf{y} - \mathbf{H}\mathbf{y}
\in
\mathrm{col}(\mathbf{X})^\perp.
\]</span></p>
<p>Portanto,</p>
<p><span class="math display">\[
\mathbf{y}
=
\mathbf{H}\mathbf{y}
+
(\mathbf{I}-\mathbf{H})\mathbf{y}.
\]</span></p>
<p>Definindo</p>
<p><span class="math display">\[
\mathbf{M} = \mathbf{I}_n - \mathbf{H},
\]</span></p>
<p>obtém-se a projeção complementar sobre o subespaço ortogonal.</p>
</section>
<section id="propriedades-da-matriz-residual" class="level4" data-number="14.4.0.3">
<h4 data-number="14.4.0.3" class="anchored" data-anchor-id="propriedades-da-matriz-residual"><span class="header-section-number">14.4.0.3</span> Propriedades da Matriz Residual</h4>
<p>A matriz</p>
<p><span class="math display">\[
\mathbf{M} = \mathbf{I}_n - \mathbf{H}
\]</span></p>
<p>satisfaz:</p>
<ul>
<li><span class="math inline">\(\mathbf{M}^\top = \mathbf{M}\)</span>,</li>
<li><span class="math inline">\(\mathbf{M}^2 = \mathbf{M}\)</span>,</li>
<li><span class="math inline">\(\mathbf{H}\mathbf{M} = \mathbf{0}\)</span>,</li>
<li><span class="math inline">\(\mathbf{M}\mathbf{H} = \mathbf{0}\)</span>.</li>
</ul>
<p>Essas propriedades garantem que os subespaços são ortogonais e complementares.</p>
</section>
<section id="decomposição-do-vetor-de-respostas" class="level4" data-number="14.4.0.4">
<h4 data-number="14.4.0.4" class="anchored" data-anchor-id="decomposição-do-vetor-de-respostas"><span class="header-section-number">14.4.0.4</span> Decomposição do Vetor de Respostas</h4>
<p>Aplicando as matrizes ao vetor <span class="math inline">\(\mathbf{Y}\)</span>:</p>
<p><span class="math display">\[
\mathbf{Y}
=
\mathbf{H}\mathbf{Y}
+
\mathbf{M}\mathbf{Y}
=
\hat{\mathbf{Y}}
+
\hat{\boldsymbol{\varepsilon}}.
\]</span></p>
<p>em que</p>
<ul>
<li><span class="math inline">\(\hat{\mathbf{Y}} = \mathbf{H}\mathbf{Y}\)</span> pertence ao espaço coluna;</li>
<li><span class="math inline">\(\hat{\boldsymbol{\varepsilon}} = \mathbf{M}\mathbf{Y}\)</span> pertence ao complemento ortogonal.</li>
</ul>
<p>A ortogonalidade implica</p>
<p><span class="math display">\[
\hat{\mathbf{Y}}^\top \hat{\boldsymbol{\varepsilon}} = 0.
\]</span></p>
<p>Essa identidade é a base da decomposição da soma de quadrados total.</p>
</section>
<section id="traço-posto-e-autovalores" class="level4" data-number="14.4.0.5">
<h4 data-number="14.4.0.5" class="anchored" data-anchor-id="traço-posto-e-autovalores"><span class="header-section-number">14.4.0.5</span> Traço, Posto e Autovalores</h4>
<p>Para matrizes idempotentes e simétricas, os autovalores são apenas 0 ou 1.</p>
<p>Se</p>
<p><span class="math display">\[
\operatorname{rank}(\mathbf{X}) = p+1,
\]</span></p>
<p>então:</p>
<ul>
<li><span class="math inline">\(\mathbf{H}\)</span> possui <span class="math inline">\(p+1\)</span> autovalores iguais a 1,</li>
<li>e <span class="math inline">\(n-(p+1)\)</span> autovalores iguais a 0.</li>
</ul>
<p>Assim,</p>
<p><span class="math display">\[
\mathrm{tr}(\mathbf{H}) = p+1.
\]</span></p>
<p>De forma análoga,</p>
<p><span class="math display">\[
\mathrm{tr}(\mathbf{M}) = n - p - 1.
\]</span></p>
<p>Como o traço de uma matriz idempotente simétrica coincide com seu posto, essas quantidades correspondem às dimensões dos subespaços projetados (ver <span class="citation" data-cites="harville1997">Harville (<a href="references.html#ref-harville1997" role="doc-biblioref">1997</a>)</span>).</p>
</section>
<section id="conexão-com-somas-de-quadrados" class="level4" data-number="14.4.0.6">
<h4 data-number="14.4.0.6" class="anchored" data-anchor-id="conexão-com-somas-de-quadrados"><span class="header-section-number">14.4.0.6</span> Conexão com Somas de Quadrados</h4>
<p>A soma de quadrados ajustada pode ser escrita como</p>
<p><span class="math display">\[
\mathbf{Y}^\top \mathbf{H} \mathbf{Y}.
\]</span></p>
<p>A soma de quadrados residual é</p>
<p><span class="math display">\[
\mathbf{Y}^\top \mathbf{M} \mathbf{Y}.
\]</span></p>
<p>Como <span class="math inline">\(\mathbf{H}\)</span> e <span class="math inline">\(\mathbf{M}\)</span> projetam sobre subespaços ortogonais,</p>
<p><span class="math display">\[
\mathbf{Y}^\top \mathbf{Y}
=
\mathbf{Y}^\top \mathbf{H} \mathbf{Y}
+
\mathbf{Y}^\top \mathbf{M} \mathbf{Y}.
\]</span></p>
<p>Essa identidade é puramente geométrica e antecede qualquer consideração probabilística.</p>
</section>
<section id="relação-com-diagnóstico" class="level4" data-number="14.4.0.7">
<h4 data-number="14.4.0.7" class="anchored" data-anchor-id="relação-com-diagnóstico"><span class="header-section-number">14.4.0.7</span> Relação com Diagnóstico</h4>
<p>A diagonal de <span class="math inline">\(\mathbf{H}\)</span> contém as alavancagens:</p>
<p><span class="math display">\[
h_{ii} = (\mathbf{H})_{ii}.
\]</span></p>
<p>Essas quantidades medem o grau de influência estrutural da <span class="math inline">\(i\)</span>-ésima observação no ajuste, pois determinam o peso da projeção sobre o espaço coluna (ver <span class="citation" data-cites="weisberg2005">Weisberg (<a href="references.html#ref-weisberg2005" role="doc-biblioref">2005</a>)</span>).</p>
<p>Valores elevados de <span class="math inline">\(h_{ii}\)</span> indicam observações que ocupam posições extremas no espaço das covariáveis.</p>
<p>A matriz de projeção sintetiza, portanto, três dimensões fundamentais do modelo linear:</p>
<ol type="1">
<li>Estrutura geométrica (projeção ortogonal);</li>
<li>Estrutura algébrica (idempotência e posto);</li>
<li>Estrutura estatística (somas de quadrados e graus de liberdade).</li>
</ol>
</section>
</section>
<section id="diferenciação-matricial-e-estimação-por-mínimos-quadrados" class="level2" data-number="14.5">
<h2 data-number="14.5" class="anchored" data-anchor-id="diferenciação-matricial-e-estimação-por-mínimos-quadrados"><span class="header-section-number">14.5</span> Diferenciação Matricial e Estimação por Mínimos Quadrados</h2>
<p>A estimação por mínimos quadrados consiste na minimização da soma de quadrados dos resíduos,</p>
<p><span class="math display">\[
S(\boldsymbol{\beta})
=
\|\mathbf{Y} - \mathbf{X}\boldsymbol{\beta}\|^2
=
(\mathbf{Y} - \mathbf{X}\boldsymbol{\beta})^\top
(\mathbf{Y} - \mathbf{X}\boldsymbol{\beta}).
\]</span></p>
<p>Essa função é uma forma quadrática em <span class="math inline">\(\boldsymbol{\beta}\)</span>. Para compreender sua estrutura, é útil expandi-la explicitamente:</p>
<p><span class="math display">\[
S(\boldsymbol{\beta})
=
\mathbf{Y}^\top \mathbf{Y}
-
2\boldsymbol{\beta}^\top \mathbf{X}^\top \mathbf{Y}
+
\boldsymbol{\beta}^\top \mathbf{X}^\top \mathbf{X} \boldsymbol{\beta}.
\]</span></p>
<p>Observa-se que:</p>
<ul>
<li><span class="math inline">\(\mathbf{Y}^\top \mathbf{Y}\)</span> é constante em relação a <span class="math inline">\(\boldsymbol{\beta}\)</span>;</li>
<li><span class="math inline">\(\boldsymbol{\beta}^\top \mathbf{X}^\top \mathbf{Y}\)</span> é termo linear;</li>
<li><span class="math inline">\(\boldsymbol{\beta}^\top \mathbf{X}^\top \mathbf{X} \boldsymbol{\beta}\)</span> é forma quadrática.</li>
</ul>
<p>A função objetivo é, portanto, um polinômio quadrático convexo sempre que <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span> for definida positiva.</p>
<section id="derivadas-matriciais-fundamentais" class="level3" data-number="14.5.1">
<h3 data-number="14.5.1" class="anchored" data-anchor-id="derivadas-matriciais-fundamentais"><span class="header-section-number">14.5.1</span> Derivadas Matriciais Fundamentais</h3>
<p>As identidades de cálculo matricial utilizadas a seguir são sistematizadas em <span class="citation" data-cites="abadir2005">Abadir; Magnus (<a href="references.html#ref-abadir2005" role="doc-biblioref">2005</a>)</span>.</p>
<ol type="1">
<li><p><span class="math display">\[
\frac{\partial (\mathbf{a}^\top \mathbf{x})}{\partial \mathbf{x}}
=
\mathbf{a}
\]</span></p></li>
<li><p><span class="math display">\[
\frac{\partial (\mathbf{x}^\top \mathbf{A}\mathbf{x})}{\partial \mathbf{x}}
=
(\mathbf{A} + \mathbf{A}^\top)\mathbf{x}
\]</span></p></li>
</ol>
<p>Em particular, se <span class="math inline">\(\mathbf{A}\)</span> é simétrica,</p>
<p><span class="math display">\[
\frac{\partial (\mathbf{x}^\top \mathbf{A}\mathbf{x})}{\partial \mathbf{x}}
=
2\mathbf{A}\mathbf{x}.
\]</span></p>
<ol start="3" type="1">
<li><p><span class="math display">\[
\frac{\partial (\mathbf{x}^\top \mathbf{A}\mathbf{b})}{\partial \mathbf{x}}
=
\mathbf{A}^\top \mathbf{b}
\]</span></p></li>
<li><p><span class="math display">\[
\frac{\partial \mathrm{tr}(\mathbf{A}\mathbf{X})}{\partial \mathbf{X}}
=
\mathbf{A}^\top
\]</span></p></li>
<li><p><span class="math display">\[
\frac{\partial
(\mathbf{Y} - \mathbf{X}\boldsymbol{\beta})^\top
(\mathbf{Y} - \mathbf{X}\boldsymbol{\beta})
}
{\partial \boldsymbol{\beta}}
=
-2\mathbf{X}^\top(\mathbf{Y} - \mathbf{X}\boldsymbol{\beta}).
\]</span></p></li>
</ol>
</section>
<section id="derivação-das-equações-normais" class="level3" data-number="14.5.2">
<h3 data-number="14.5.2" class="anchored" data-anchor-id="derivação-das-equações-normais"><span class="header-section-number">14.5.2</span> Derivação das Equações Normais</h3>
<p>Aplicando a derivada à função <span class="math inline">\(S(\boldsymbol{\beta})\)</span> (ver <span class="citation" data-cites="abadir2005">Abadir; Magnus (<a href="references.html#ref-abadir2005" role="doc-biblioref">2005</a>)</span>):</p>
<p><span class="math display">\[
\nabla_{\boldsymbol{\beta}} S(\boldsymbol{\beta})
=
-2\mathbf{X}^\top(\mathbf{Y} - \mathbf{X}\boldsymbol{\beta}).
\]</span></p>
<p>Igualando o gradiente a zero:</p>
<p><span class="math display">\[
\mathbf{X}^\top(\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}}) = 0.
\]</span></p>
<p>Reorganizando,</p>
<p><span class="math display">\[
\mathbf{X}^\top \mathbf{X}\hat{\boldsymbol{\beta}}
=
\mathbf{X}^\top \mathbf{Y}.
\]</span></p>
<p>Essas são as <strong>equações normais</strong>.</p>
<p>Se <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span> é invertível, isto é, se as colunas de <span class="math inline">\(\mathbf{X}\)</span> são linearmente independentes, obtém-se a solução única:</p>
<p><span class="math display">\[
\hat{\boldsymbol{\beta}}
=
(\mathbf{X}^\top \mathbf{X})^{-1}
\mathbf{X}^\top \mathbf{Y}.
\]</span></p>
</section>
<section id="interpretação-algébrica" class="level3" data-number="14.5.3">
<h3 data-number="14.5.3" class="anchored" data-anchor-id="interpretação-algébrica"><span class="header-section-number">14.5.3</span> Interpretação Algébrica</h3>
<p>A condição</p>
<p><span class="math display">\[
\mathbf{X}^\top(\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}})=0
\]</span></p>
<p>implica</p>
<p><span class="math display">\[
\mathbf{X}^\top \hat{\boldsymbol{\varepsilon}} = 0,
\]</span></p>
<p>ou seja, o vetor residual é ortogonal a cada coluna de <span class="math inline">\(\mathbf{X}\)</span>.</p>
</section>
<section id="interpretação-geométrica-1" class="level3" data-number="14.5.4">
<h3 data-number="14.5.4" class="anchored" data-anchor-id="interpretação-geométrica-1"><span class="header-section-number">14.5.4</span> Interpretação Geométrica</h3>
<p>A minimização de <span class="math inline">\(S(\boldsymbol{\beta})\)</span> equivale a resolver</p>
<p><span class="math display">\[
\min_{\mathbf{v} \in \mathrm{col}(\mathbf{X})}
\|\mathbf{Y} - \mathbf{v}\|^2.
\]</span></p>
<p>Portanto,</p>
<p><span class="math display">\[
\hat{\mathbf{Y}} = \mathbf{X}\hat{\boldsymbol{\beta}}
\]</span></p>
<p>é a projeção ortogonal de <span class="math inline">\(\mathbf{Y}\)</span> sobre <span class="math inline">\(\mathrm{col}(\mathbf{X})\)</span>. Essa caracterização independe de qualquer hipótese probabilística.</p>
</section>
</section>
<section id="estrutura-matricial-para-diagnóstico-e-inferência" class="level2" data-number="14.6">
<h2 data-number="14.6" class="anchored" data-anchor-id="estrutura-matricial-para-diagnóstico-e-inferência"><span class="header-section-number">14.6</span> Estrutura Matricial para Diagnóstico e Inferência</h2>
<p>A formulação matricial do modelo linear não se limita à obtenção do estimador de mínimos quadrados. Ela estrutura integralmente os procedimentos de diagnóstico e prepara o terreno para a inferência estatística.</p>
<p>Recordemos a decomposição fundamental:</p>
<p><span class="math display">\[
\mathbf{Y}
=
\mathbf{H}\mathbf{Y}
+
\mathbf{M}\mathbf{Y}
=
\hat{\mathbf{Y}}
+
\hat{\boldsymbol{\varepsilon}}.
\]</span></p>
<p>Essa identidade organiza o vetor de respostas em duas componentes ortogonais pertencentes a subespaços complementares.</p>
<section id="alavancagem-e-estrutura-da-matriz-mathbfh" class="level3" data-number="14.6.1">
<h3 data-number="14.6.1" class="anchored" data-anchor-id="alavancagem-e-estrutura-da-matriz-mathbfh"><span class="header-section-number">14.6.1</span> Alavancagem e Estrutura da Matriz <span class="math inline">\(\mathbf{H}\)</span></h3>
<p>A diagonal da matriz de projeção</p>
<p><span class="math display">\[
h_{ii} = (\mathbf{H})_{ii}
\]</span></p>
<p>mensura o quanto a <span class="math inline">\(i\)</span>-ésima observação contribui estruturalmente para sua própria projeção.</p>
<p>Explicitamente,</p>
<p><span class="math display">\[
h_{ii}
=
\mathbf{x}_i^\top
(\mathbf{X}^\top \mathbf{X})^{-1}
\mathbf{x}_i,
\]</span></p>
<p>em que <span class="math inline">\(\mathbf{x}_i^\top\)</span> é a <span class="math inline">\(i\)</span>-ésima linha da matriz <span class="math inline">\(\mathbf{X}\)</span>.</p>
<p>Propriedades fundamentais:</p>
<ul>
<li><span class="math inline">\(0 \le h_{ii} \le 1\)</span>;</li>
<li><span class="math inline">\(\sum_{i=1}^n h_{ii} = p+1\)</span>;</li>
<li>observações com valores elevados de <span class="math inline">\(h_{ii}\)</span> ocupam posições extremas no espaço das covariáveis.</li>
</ul>
</section>
<section id="estrutura-dos-resíduos" class="level3" data-number="14.6.2">
<h3 data-number="14.6.2" class="anchored" data-anchor-id="estrutura-dos-resíduos"><span class="header-section-number">14.6.2</span> Estrutura dos Resíduos</h3>
<p>Os resíduos podem ser escritos como</p>
<p><span class="math display">\[
\hat{\boldsymbol{\varepsilon}}
=
\mathbf{M}\mathbf{Y}.
\]</span></p>
<p>Como <span class="math inline">\(\mathbf{M}\)</span> é simétrica e idempotente,</p>
<p><span class="math display">\[
\mathbf{M}^2 = \mathbf{M},
\qquad
\mathbf{M}^\top = \mathbf{M}.
\]</span></p>
<p>Além disso,</p>
<p><span class="math display">\[
\mathbf{X}^\top \hat{\boldsymbol{\varepsilon}} = \mathbf{0},
\]</span></p>
<p>o que garante que os resíduos são ortogonais às colunas de <span class="math inline">\(\mathbf{X}\)</span>.</p>
<p>Essa ortogonalidade fundamenta:</p>
<ul>
<li>a decomposição das somas de quadrados;</li>
<li>a independência geométrica entre componentes ajustadas e residuais;</li>
<li>a contagem de graus de liberdade.</li>
</ul>
</section>
<section id="somas-de-quadrados-em-forma-matricial" class="level3" data-number="14.6.3">
<h3 data-number="14.6.3" class="anchored" data-anchor-id="somas-de-quadrados-em-forma-matricial"><span class="header-section-number">14.6.3</span> Somas de Quadrados em Forma Matricial</h3>
<p>A soma de quadrados total pode ser escrita como</p>
<p><span class="math display">\[
\mathbf{Y}^\top \mathbf{Y}.
\]</span></p>
<p>A soma de quadrados explicada pelo modelo é</p>
<p><span class="math display">\[
\mathbf{Y}^\top \mathbf{H} \mathbf{Y}.
\]</span></p>
<p>A soma de quadrados residual é</p>
<p><span class="math display">\[
\mathbf{Y}^\top \mathbf{M} \mathbf{Y}.
\]</span></p>
<p>Como <span class="math inline">\(\mathbf{H}\)</span> e <span class="math inline">\(\mathbf{M}\)</span> projetam sobre subespaços ortogonais,</p>
<p><span class="math display">\[
\mathbf{Y}^\top \mathbf{Y}
=
\mathbf{Y}^\top \mathbf{H} \mathbf{Y}
+
\mathbf{Y}^\top \mathbf{M} \mathbf{Y}.
\]</span></p>
<p>Essa identidade é puramente algébrica e independe de qualquer suposição probabilística.</p>
</section>
<section id="postos-e-graus-de-liberdade" class="level3" data-number="14.6.4">
<h3 data-number="14.6.4" class="anchored" data-anchor-id="postos-e-graus-de-liberdade"><span class="header-section-number">14.6.4</span> Postos e Graus de Liberdade</h3>
<p>Como visto anteriormente,</p>
<p><span class="math display">\[
\mathrm{tr}(\mathbf{H}) = p+1,
\qquad
\mathrm{tr}(\mathbf{M}) = n - p - 1.
\]</span></p>
<p>Para matrizes simétricas idempotentes, o traço coincide com o posto. Portanto:</p>
<ul>
<li>o subespaço ajustado tem dimensão <span class="math inline">\(p+1\)</span>;</li>
<li>o subespaço residual tem dimensão <span class="math inline">\(n-p-1\)</span>.</li>
</ul>
<p>Essas dimensões serão reinterpretadas, no contexto probabilístico, como graus de liberdade associados às somas de quadrados.</p>


<div id="refs" class="references csl-bib-body" data-entry-spacing="1" role="list" style="display: none">
<div id="ref-abadir2005" class="csl-entry" role="listitem">
ABADIR, Karim M.; MAGNUS, Jan R. <strong>Matrix Algebra</strong>. Cambridge: Cambridge University Press, 2005.
</div>
<div id="ref-golub2013" class="csl-entry" role="listitem">
GOLUB, Gene H.; VAN LOAN, Charles F. <strong>Matrix Computations</strong>. 4. ed. Baltimore: Johns Hopkins University Press, 2013.
</div>
<div id="ref-harville1997" class="csl-entry" role="listitem">
HARVILLE, David A. <strong>Matrix Algebra From a Statistician’s Perspective</strong>. New York: Springer, 1997.
</div>
<div id="ref-rencher2012" class="csl-entry" role="listitem">
RENCHER, Alvin C.; CHRISTENSEN, William F. <strong>Methods of Multivariate Analysis</strong>. 3. ed. Hoboken: Wiley, 2012.
</div>
<div id="ref-weisberg2005" class="csl-entry" role="listitem">
WEISBERG, Sanford. <strong>Applied Linear Regression</strong>. New York: Wiley, 2005.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiada");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiada");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ap_listas.html" class="pagination-link" aria-label="Lista de Siglas e Símbolos">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Lista de Siglas e Símbolos</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ap_normal.html" class="pagination-link" aria-label="Distribuição Normal">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Distribuição Normal</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>